{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0461d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from utils_common import get_db_engine, encode_dataframe\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# **************************************\n",
    "# keras.models.Sequential()\n",
    "# **************************************\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # keras, not kera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24955b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# Neural Net Configuration Variables\n",
    "# **************************************\n",
    "\n",
    "# ******************\n",
    "# Data Configuration\n",
    "tablename = 'people_vet_join'\n",
    "y_column = 'TotalVets'\n",
    "\n",
    "# ******************\n",
    "# First Layer Configuration\n",
    "kS_nn_first_units       = 8\n",
    "kS_nn_first_activation  = \"relu\"\n",
    "\n",
    "# ******************\n",
    "# Output Layer Configuration\n",
    "kS_nn_output_units      = 1\n",
    "kS_nn_output_activation = \"sigmoid\"\n",
    "\n",
    "# ******************\n",
    "# Deep Learning Configuration\n",
    "kS_nn_deep_layers       = [\n",
    "    # Comment out the next two lines to disable \"deep learning\"\n",
    "    {\"units\": 16,\n",
    "     \"activation\": \"relu\"},\n",
    "\n",
    "    # Add more layers with\n",
    "    #    {\"units\": <units>,\n",
    "    #     \"activation\": <activation>},\n",
    "                     ]\n",
    "\n",
    "# ******************\n",
    "# Compiler Configuration\n",
    "kS_nn_compile_loss      = \"binary_crossentropy\"\n",
    "kS_nn_compile_optimizer = \"adam\"\n",
    "kS_nn_compile_metrics   = [\"accuracy\"]\n",
    "\n",
    "# ******************\n",
    "# Training Configuration\n",
    "kS_nn_train_epochs      = 100\n",
    "\n",
    "# ******************\n",
    "# Output File\n",
    "kS_nn_file              = \"kS-Enlistment_Prediction.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1e741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and read data\n",
    "# combined_df = getfromdatabase{postres}\n",
    "\n",
    "try:\n",
    "    db_engine = get_db_engine()\n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to connect to database engine.\\n\", e)\n",
    "\n",
    "try:\n",
    "    combined_df = pd.read_sql_table(tablename, db_engine)\n",
    "except Exception as e:\n",
    "    print(f\"\\nFailed to read table {tablename} on db_engine {db_engine}.\\n\", e)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f349417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = combined_df[['State', 'County']]\n",
    "combined_df = combined_df.drop(columns=['FIPS', 'State', 'County'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b65dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PopChangeRate1819</th>\n",
       "      <th>PopChangeRate1019</th>\n",
       "      <th>TotalPopEst2019</th>\n",
       "      <th>NetMigrationRate1019</th>\n",
       "      <th>NaturalChangeRate1019</th>\n",
       "      <th>Net_International_Migration_Rate_2010_2019</th>\n",
       "      <th>PopChangeRate0010</th>\n",
       "      <th>NetMigrationRate0010</th>\n",
       "      <th>NaturalChangeRate0010</th>\n",
       "      <th>Immigration_Rate_2000_2010</th>\n",
       "      <th>...</th>\n",
       "      <th>WhiteVetsPct</th>\n",
       "      <th>BlackVetsPct</th>\n",
       "      <th>HispanicVetsPct</th>\n",
       "      <th>OtherRaceVetsPct</th>\n",
       "      <th>LessThanHSVetsPct</th>\n",
       "      <th>HighSchOnlyVetsPct</th>\n",
       "      <th>SomeCollegeVetsPct</th>\n",
       "      <th>CollegeDegreeVetsPct</th>\n",
       "      <th>EmployeedVetsPct</th>\n",
       "      <th>UnemployeedVetsPct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.317</td>\n",
       "      <td>2.461</td>\n",
       "      <td>4903185</td>\n",
       "      <td>1.059</td>\n",
       "      <td>1.402</td>\n",
       "      <td>0.809</td>\n",
       "      <td>7.48</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.222931</td>\n",
       "      <td>...</td>\n",
       "      <td>72.534198</td>\n",
       "      <td>22.945607</td>\n",
       "      <td>2.022065</td>\n",
       "      <td>3.059596</td>\n",
       "      <td>6.396034</td>\n",
       "      <td>28.257189</td>\n",
       "      <td>37.385370</td>\n",
       "      <td>27.961408</td>\n",
       "      <td>71.330519</td>\n",
       "      <td>4.319786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605</td>\n",
       "      <td>2.001</td>\n",
       "      <td>55869</td>\n",
       "      <td>0.686</td>\n",
       "      <td>1.315</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>24.96</td>\n",
       "      <td>11.87</td>\n",
       "      <td>5.46</td>\n",
       "      <td>-0.010222</td>\n",
       "      <td>...</td>\n",
       "      <td>84.028832</td>\n",
       "      <td>9.673748</td>\n",
       "      <td>5.576631</td>\n",
       "      <td>1.119120</td>\n",
       "      <td>3.007812</td>\n",
       "      <td>20.859375</td>\n",
       "      <td>31.621094</td>\n",
       "      <td>44.511719</td>\n",
       "      <td>86.549340</td>\n",
       "      <td>3.558460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.469</td>\n",
       "      <td>21.911</td>\n",
       "      <td>223234</td>\n",
       "      <td>21.001</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.714</td>\n",
       "      <td>29.80</td>\n",
       "      <td>26.17</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.584455</td>\n",
       "      <td>...</td>\n",
       "      <td>90.621980</td>\n",
       "      <td>5.360321</td>\n",
       "      <td>1.439251</td>\n",
       "      <td>2.929360</td>\n",
       "      <td>3.612916</td>\n",
       "      <td>27.659792</td>\n",
       "      <td>36.676731</td>\n",
       "      <td>32.050560</td>\n",
       "      <td>74.927707</td>\n",
       "      <td>3.430532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.748</td>\n",
       "      <td>-9.664</td>\n",
       "      <td>24686</td>\n",
       "      <td>-8.797</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.828365</td>\n",
       "      <td>...</td>\n",
       "      <td>59.563253</td>\n",
       "      <td>37.349398</td>\n",
       "      <td>1.054217</td>\n",
       "      <td>3.087349</td>\n",
       "      <td>12.349398</td>\n",
       "      <td>39.834337</td>\n",
       "      <td>36.746988</td>\n",
       "      <td>11.069277</td>\n",
       "      <td>49.752066</td>\n",
       "      <td>9.966777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121</td>\n",
       "      <td>-2.081</td>\n",
       "      <td>22394</td>\n",
       "      <td>-2.099</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.525</td>\n",
       "      <td>10.03</td>\n",
       "      <td>6.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.341485</td>\n",
       "      <td>...</td>\n",
       "      <td>79.134682</td>\n",
       "      <td>18.492673</td>\n",
       "      <td>2.372645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.901510</td>\n",
       "      <td>54.708843</td>\n",
       "      <td>22.286125</td>\n",
       "      <td>16.103523</td>\n",
       "      <td>56.901408</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PopChangeRate1819  PopChangeRate1019  TotalPopEst2019  \\\n",
       "0              0.317              2.461          4903185   \n",
       "1              0.605              2.001            55869   \n",
       "2              2.469             21.911           223234   \n",
       "3             -0.748             -9.664            24686   \n",
       "4              0.121             -2.081            22394   \n",
       "\n",
       "   NetMigrationRate1019  NaturalChangeRate1019  \\\n",
       "0                 1.059                  1.402   \n",
       "1                 0.686                  1.315   \n",
       "2                21.001                  0.910   \n",
       "3                -8.797                 -0.867   \n",
       "4                -2.099                  0.017   \n",
       "\n",
       "   Net_International_Migration_Rate_2010_2019  PopChangeRate0010  \\\n",
       "0                                       0.809               7.48   \n",
       "1                                      -0.029              24.96   \n",
       "2                                       0.714              29.80   \n",
       "3                                       0.161              -5.44   \n",
       "4                                       0.525              10.03   \n",
       "\n",
       "   NetMigrationRate0010  NaturalChangeRate0010  Immigration_Rate_2000_2010  \\\n",
       "0                  3.30                   3.30                    1.222931   \n",
       "1                 11.87                   5.46                   -0.010222   \n",
       "2                 26.17                   3.32                    1.584455   \n",
       "3                 -4.80                   2.29                    1.828365   \n",
       "4                  6.43                   2.10                    0.341485   \n",
       "\n",
       "   ...  WhiteVetsPct  BlackVetsPct  HispanicVetsPct  OtherRaceVetsPct  \\\n",
       "0  ...     72.534198     22.945607         2.022065          3.059596   \n",
       "1  ...     84.028832      9.673748         5.576631          1.119120   \n",
       "2  ...     90.621980      5.360321         1.439251          2.929360   \n",
       "3  ...     59.563253     37.349398         1.054217          3.087349   \n",
       "4  ...     79.134682     18.492673         2.372645          0.000000   \n",
       "\n",
       "   LessThanHSVetsPct  HighSchOnlyVetsPct  SomeCollegeVetsPct  \\\n",
       "0           6.396034           28.257189           37.385370   \n",
       "1           3.007812           20.859375           31.621094   \n",
       "2           3.612916           27.659792           36.676731   \n",
       "3          12.349398           39.834337           36.746988   \n",
       "4           6.901510           54.708843           22.286125   \n",
       "\n",
       "   CollegeDegreeVetsPct  EmployeedVetsPct  UnemployeedVetsPct  \n",
       "0             27.961408         71.330519            4.319786  \n",
       "1             44.511719         86.549340            3.558460  \n",
       "2             32.050560         74.927707            3.430532  \n",
       "3             11.069277         49.752066            9.966777  \n",
       "4             16.103523         56.901408            0.000000  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4f6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target arrays\n",
    "y = combined_df[y_column].values\n",
    "X = combined_df.drop([y_column],1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "379826eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4042f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b6e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************\n",
    "# **************************************\n",
    "# Neural Network - Sequential\n",
    "# **************************************\n",
    "# **************************************\n",
    "def run_model_sequential():\n",
    "\n",
    "    # Define the model\n",
    "    number_input_features = len(X_train_scaled[0])\n",
    "\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=kS_nn_first_units,\n",
    "                input_dim=number_input_features,\n",
    "                activation=kS_nn_first_activation))\n",
    "\n",
    "    # Additional hidden layers\n",
    "    for layer in kS_nn_deep_layers:\n",
    "        nn.add(tf.keras.layers.Dense(units=layer['units'],\n",
    "                                     activation=layer['activation']))\n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=kS_nn_output_units, activation=kS_nn_output_activation))\n",
    "\n",
    "    # Check the structure of the model\n",
    "    print(nn.summary())\n",
    "\n",
    "    # Compile the model\n",
    "    nn.compile(loss=kS_nn_compile_loss, optimizer=kS_nn_compile_optimizer, metrics=kS_nn_compile_metrics)\n",
    "\n",
    "    # Train the model\n",
    "    fit_model = nn.fit(X_train_scaled, y_train,epochs=kS_nn_train_epochs)\n",
    "\n",
    "    # Evaluate the model using the test data\n",
    "    model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "    nn.save(kS_nn_file)\n",
    "\n",
    "# end run_model_sequential()\n",
    "# **************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc9abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 816       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,521\n",
      "Trainable params: 1,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "78/78 [==============================] - 0s 817us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 0s 781us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 0s 699us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 0s 716us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 0s 685us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 0s 772us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 0s 768us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 0s 735us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 0s 713us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 0s 751us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 0s 776us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 0s 761us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 0s 706us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 0s 763us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 0s 791us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 0s 740us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 0s 722us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 0s 766us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 0s 757us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 0s 747us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 0s 730us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 0s 747us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 0s 779us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 0s 731us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 0s 744us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 0s 765us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 0s 721us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 0s 715us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - 0s 733us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - 0s 755us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - 0s 781us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - 0s 840us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - 0s 776us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - 0s 768us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - 0s 731us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - 0s 758us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - 0s 729us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - 0s 731us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - 0s 717us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - 0s 709us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - 0s 750us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - 0s 747us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - 0s 711us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - 0s 751us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - 0s 801us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - 0s 767us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - 0s 856us/step - loss: nan - accuracy: 0.0000e+00 0s - loss: nan - accuracy: 0.0000e+0\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - 0s 831us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - 0s 796us/step - loss: nan - accuracy: 0.0000e+00\n",
      "26/26 - 0s - loss: nan - accuracy: 0.0012\n",
      "Loss: nan, Accuracy: 0.001212121220305562\n"
     ]
    }
   ],
   "source": [
    "# **************************************\n",
    "# **************************************\n",
    "# **************************************\n",
    "run_model_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
